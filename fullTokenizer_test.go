package go_bert_tokenizer

import (
	"testing"
)

func TestTokenize(t *testing.T) {

	type fields struct {
		Text string
	}

	tests := []struct {
		name   string
		fields fields
		want   []int32
	}{
		{
			"Test case: 1",
			fields{
				Text: "This is ā text!!!",
			},
			[]int32{101, 2023, 2003, 1037, 3793, 999, 999, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
		{
			"Test case: 2",
			fields{
				Text: "This sentence is: 你好呀!很高興認識你（我是XXX） ",
			},
			[]int32{101, 2023, 6251, 2003, 1024, 100, 100, 100, 999, 100, 1981, 100, 100, 100, 100, 1987, 1855, 100, 22038, 2595, 1988, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
		{
			"Test case: 3",
			fields{
				Text: "This sentence is: Σήμερα είναι τα γενέθλιά μου",
			},
			[]int32{101, 2023, 6251, 2003, 1024, 1173, 24824, 29728, 29723, 29732, 14608, 1159, 18199, 16177, 14608, 18199, 1174, 14608, 1157, 29723, 16177, 29723, 29725, 29727, 27432, 1166, 26789, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
		{
			"Test case: 4",
			fields{
				Text: "This sentence is: Bugün benim doğum günüm",
			},
			[]int32{101, 2023, 6251, 2003, 1024, 11829, 4609, 3841, 5714, 3899, 2819, 3282, 2819, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
		{
			"Test case: 5",
			fields{
				Text: "This sentence is: 今日は私の誕生日です",
			},
			[]int32{101, 2023, 6251, 2003, 1024, 100, 1864, 1672, 100, 1671, 100, 1910, 1864, 1665, 30184, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
		{
			"Test case: 6",
			fields{
				Text: "Сегодня мой день рождения",
			},
			[]int32{101, 1196, 15290, 29741, 14150, 29742, 18947, 17432, 1191, 14150, 10325, 1184, 15290, 18947, 23742, 1195, 14150, 29743, 29742, 15290, 18947, 23483, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
		{
			"Test case: 7",
			fields{
				Text: "안녕하세요 오늘은 제 생일이에요 만나서 반가워요",
			},
			[]int32{101, 1463, 30006, 30021, 29992, 30010, 30025, 30005, 30006, 29997, 30009, 29999, 30013, 1463, 30011, 29992, 30017, 30022, 29999, 30017, 30021, 1464, 30009, 1461, 30007, 30025, 29999, 30019, 30022, 29999, 30019, 29999, 30009, 29999, 30013, 1459, 30006, 30021, 29992, 30006, 29997, 30008, 1460, 30006, 30021, 29991, 30006, 29999, 30015, 29999, 30013, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
		{
			"Test case: 8",
			fields{
				Text: "สวัสดี วันนี้เป็นวันเกิดของฉัน ยินดีที่ได้รู้จัก",
			},
			[]int32{101, 100, 100, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
		{
			"Test case: 9",
			fields{
				Text: "In documentis nostris, prima sententia est numerus 1º.",
			},
			[]int32{101, 1999, 6254, 2483, 16839, 18886, 2015, 1010, 21111, 2741, 4765, 2401, 9765, 16371, 5017, 2271, 1015, 29662, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
		{
			"Test case: 10",
			fields{
				Text: "سلام، امروز تولد من است، از آشنایی با شما خوشحالم",
			},
			[]int32{101, 1282, 23673, 25573, 22192, 1268, 1270, 22192, 17149, 29836, 29823, 1273, 29836, 23673, 15394, 1295, 15915, 1270, 29824, 29817, 1268, 1270, 29823, 1270, 29825, 15915, 25573, 24830, 24830, 1271, 25573, 1283, 22192, 25573, 1277, 29836, 29825, 29820, 25573, 23673, 22192, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0},
		},
	}

	voc, _ := FromFile("./tmp/vocab.txt")
	tkz := NewFullTokenizer(voc, 128, true)

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			encode := tkz.Tokenize(tt.fields.Text)
			if len(encode.TokenIDs) != len(tt.want) {
				t.Errorf("Tokenize() length should be %d", len(tt.want))
			}
			for i, v := range tt.want {
				if encode.TokenIDs[i] != v {
					t.Errorf("%s: Tokenize() idx(%d) should be %d", tt.name, i, v)
				}
			}
		})
	}
}

func BenchmarkTokenize(b *testing.B) {
	b.ResetTimer()
	voc, _ := FromFile("./tmp/vocab.txt")
	tkz := NewFullTokenizer(voc, 128, true)
	text := "Hello world Hello This is ā text!!! 你好呀This is ā text!!! 你好呀This is ā text!!! 你好呀"

	for i := 0; i < b.N; i++ {
		tkz.Tokenize(text)
	}

	b.StopTimer()
}
